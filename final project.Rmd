---
title: "Capstone Project"
author: "Jack Stevens"
date: "2024-04-18"
output: pdf_document
---

```{r}
data <- read.csv("cardio_train.csv", sep = ';' )
```

```{r}
head(data)

``` 

```{r}
names(data)
```


```{r}
data <-  data[-1]
data['gender'] <- as.factor(data$gender)
data['cholesterol'] <-  as.factor(data$cholesterol)
data['gluc'] <-  as.factor(data$gluc)
data['smoke'] <-  as.factor(data$smoke)
data['alco'] <- as.factor(data$alco)
data['active'] <- as.factor(data$active)
data['cardio'] <-  as.factor(data$cardio)

````

```{r}
# Select only numeric predictors
numeric_data <- data[sapply(data, is.numeric)]

# If you want to exclude the outcome variable, make sure it's not numeric or handle it separately
if("outcome" %in% names(numeric_data)) {
  numeric_data <- numeric_data[, !names(numeric_data) %in% "outcome"]
}

# Show the numeric predictors
cor(numeric_data)

```

```{r}
numeric_data_scaled <- scale(numeric_data)
head(numeric_data_scaled)
```

```{r}
non_numeric_data <- data[sapply(data, is.factor)]
data <- data.frame(numeric_data_scaled, non_numeric_data)
head(data)
```

```{r}
names(data)
```

```{r}
summary(data)
```




```{r}
attach(data)

plot(cardio, age)
```


```{r}
plot(cardio, height)
```

```{r}
sum(data$cardio == 1)
sum(data$cardio == 0)
````

```{r}


model <- glm(cardio ~., data = data, family = 'binomial', control = glm.control(maxit = 100))
summary(model)
```

```{r}
p_values <-  coef(summary(model))[, "Pr(>|z|)"]

significant_predictors <- p_values[p_values < 0.05]
(sig_predictors_names <- (names(significant_predictors[-1])))
```

```{r}

model <- glm(cardio ~ age + height + weight + ap_hi + ap_lo + cholesterol + 
               gluc + smoke + alco + active, data = data, family = "binomial")

summary(model)


```

```{r}
set.seed(1)
size_d <- dim(data)[1]
train_indices <- sample(size_d, size_d * .80)


```

```{r}
method <- c('logistic Regression', 'LDA', 'QDA', 'NB', 
            "Decision Tree", "KNN", "Random Forest ")
```

```{r}
library(dplyr)
test_errors <-  numeric(7)
selected <-  data
train.X <- selected[train_indices, -which(names(selected) == "cardio")]
train.Y <- selected[train_indices, "cardio"]
test.X <- selected[-train_indices, -which(names(selected) == "cardio")]
test.Y <- selected[-train_indices, "cardio"]


#logistic Classification
glm.fit = glm(cardio ~ ., data = selected,
            subset = train_indices, family = "binomial")

#compute the estimated class probability
glm.probs = predict(glm.fit, test.X, type = "response")
glm.pred = rep(0, length(test.Y))
glm.pred[glm.probs > 0.5] = 1

(test_errors[1] = 1 - mean(glm.pred == test.Y))

``` 
 
```{r}  
library(MASS) 
  #LDA 
  lda.fit <-  lda(cardio ~ ., data = selected, 
                subset = train_indices)
  # make predictions
  lda.pred <- predict(lda.fit , test.X)
  # produce a confusion matrix
  lda.class <- lda.pred$class

  # calculate accuracy on the test set
  (test_errors[2] = 1 - mean(lda.class == test.Y))

```

```{r}  
  #QDA
  qda.fit <-  qda(cardio ~ . , data = selected,
                subset = train_indices)

  # make predictions
  qda.pred <- predict(qda.fit , test.X)
  
  # produce a confusion matrix
  qda.class <- qda.pred$class

  # calculate accuracy on the test set
  (test_errors[3] = 1 - mean(qda.class == test.Y))

```

```{r}
library(e1071)
  # NB
   nb.fit <- naiveBayes(cardio ~ . ,
                      data = selected, subset = train_indices)
  # predict class labels for the test data
  nb.class = predict(nb.fit, test.X)
  # print the confusion matrix for the test data

  # compute the prediction accuracy on the test data
  (test_errors[4] = 1 - mean(nb.class == test.Y))

```

```{r}
library(tree)
tree.cardio <- tree(cardio~., selected, subset = train_indices)

tree.pred <- predict(tree.cardio, test.X, type = "class")
table(tree.pred, test.Y)

(test_errors[5] <- 1 - mean(tree.pred ==  test.Y))

```

```{r}
### Takes a while to run 
    library(class)
    k_test_error = numeric(6)
    k <- (1:6) *2 - 1 
    
    min_test_error = 1
    k_value_test = 0
    
    for( i in 1:6){
        knn.pred <- knn(train.X, test.X, train.Y, k = 2*i - 1)
        test_error <- 1 - mean(test.Y == knn.pred)
       
        if(test_error < min_test_error){
          min_test_error <- test_error
          k_value_test <- 2*i - 1
        }
        k_test_error[i] <- test_error
      }

    
    plot(k,  k_test_error, xlab = "k",
         ylab = "test error", main = "Test error vs K")
    lines(k, k_test_error, col = 'red')
    points(k_value_test, min_test_error, col = "blue", pch = 19, cex = 2) 
    
df <- data.frame(k,  k_test_error)

df

```



```{r}
knn.pred <- knn(train.X, test.X, train.Y, k = 7)
test_error <- 1 - mean(test.Y == knn.pred)
test_errors[6] <- test_error


```

```{r}
library(randomForest)
bag.cardio <- randomForest(cardio ~. , data = selected, subset = train_indices,
                           mtry = 8, importance = TRUE)
```

```{r}
yhat.rf <- predict(bag.cardio, newdata = data[-train_indices, ])

```

```{R}
test_errors[7] = 1 - mean(yhat.rf == test.Y)
```

```{r}
library(randomForest)
rf.cardio <- randomForest(cardio ~. , data = selected, subset = train_indices, importance = TRUE)
```

```{r}
yhat.rf <- predict(rf.cardio, newdata = data[-train_indices, ])

```

```{R}
test_errrors[7] = 1 - mean(yhat.rf == test.Y)
```

```{r}
accuracy_test <- 1 - test_errors
df_interaction <- data.frame(method, test_errors, accuracy_test) 
df_sorted <- arrange(df_interaction, test_errors)
df_sorted
```
Logistic and Regression looks good. Maybe PCA / Lasso might 
help with logistic regression accuracy. This is a warming with the logistic 
regression model about converges? I don't know? 

### Pruning Random Forest

```{r}
set.seed(7)

cv.cardioTree <- cv.tree(tree.cardio, FUN = prune.misclass)
```

```{R}
names(cv.cardioTree)
cv.cardioTree
```

```{R}
par(mfrow = c(1,2))
plot(cv.cardioTree$size, cv.cardioTree$dev, type = "b")
plot(cv.cardioTree$k, cv.cardioTree$dev, type = "b")

```

```{r}
prune.cardio <- prune.misclass(tree.cardio, best = 2)
plot(prune.cardio)
text(prune.cardio, pretty = 0)
```

```{r}

tree.pred <- predict(prune.cardio, test.X, type = "class")
mean(tree.pred == test.Y)

```

Same accuracy


### Under PCA
```{r}
dim(numeric_data_scaled)
```
```{r}
dim(data)

```

```{r}

pr.out <- prcomp(numeric_data, scale = TRUE)
pca_scores <- as.data.frame(pr.out$x)

```


```{r}
pca_df <- data.frame(pca_scores, non_numeric_data)
dim(pca_df)

```



```{r}
library(dplyr)
test_errors <-  numeric(6)
selected <-  pca_df
train.X <- selected[train_indices, -which(names(selected) == "cardio")]
train.Y <- selected[train_indices, "cardio"]
test.X <- selected[-train_indices, -which(names(selected) == "cardio")]
test.Y <- selected[-train_indices, "cardio"]



```

```{R}
#logistic Classification
glm.fit = glm(cardio ~ ., data = selected,
            subset = train_indices, family = "binomial")

#compute the estimated class probability
glm.probs = predict(glm.fit, test.X, type = "response")
glm.pred = rep(0, length(test.Y))
glm.pred[glm.probs > 0.5] = 1

(test_errors[1] = 1 - mean(glm.pred == test.Y))

```


### Regulization 

```{r}
library(glmnet)

x <- as.matrix(train.X)  # Predictor matrix
y <- train.Y  # Response variable

# Fit model
glmnet_model <- cv.glmnet(x, y, family = "binomial", alpha = 1)

```

```{r}
best_lambda <- glmnet_model$lambda.min

```

```{r}
# Predicting probabilities
predicted_probabilities <- predict(glmnet_model, newx = as.matrix(test.X), type = "response", s = best_lambda)

# Predicting class labels (you might need to specify a threshold, e.g., 0.5)
predicted_classes <- ifelse(predicted_probabilities > 0.5, 1, 0)

```

#### Regulization LASSO

```{R}
1 - mean(predicted_classes == test.Y)
```
```{r}
library(glmnet)

x <- as.matrix(train.X)  # Predictor matrix
y <- train.Y  # Response variable

# Fit model
glmnet_model <- cv.glmnet(x, y, family = "binomial", alpha = 0)

```

```{r}
best_lambda <- glmnet_model$lambda.min

```

```{r}
# Predicting probabilities
predicted_probabilities <- predict(glmnet_model, newx = as.matrix(test.X), type = "response", s = best_lambda)

# Predicting class labels (you might need to specify a threshold, e.g., 0.5)
predicted_classes <- ifelse(predicted_probabilities > 0.5, 1, 0)

```

#### Regulization LASSO

```{R}
1 - mean(predicted_classes == test.Y)
```

#### Without Regulation

```{r}
test_errors[1]
```

### best Subset

```{r}
library(leaps)
results <-  regsubsets(cardio ~ ., data = data, method = 'exhaustive')
reg.summary <- summary(results)

```


```{r}
plot (reg.summary$cp , xlab = " Number of Variables ", ylab = "Cp" , type = "l" )
min_cp <- which.min(reg.summary$cp)
points (min_cp , reg.summary$cp[min_cp], col = "red" , cex = 2 ,pch = 20)
min_bic <- which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC" , type = "l" )
points(min_bic , reg.summary$bic[min_bic], col = "red" , cex = 2 ,pch = 20)
min_adjr2 <- which.min(reg.summary$adjr2)
plot(reg.summary$adjr2 , xlab = "Number of Variables",
ylab = "ADJR2" , type = "l" )
points(min_adjr2 , reg.summary$adjr2[min_adjr2], col = "red" , cex = 2 ,pch = 20)



```

```{R}
coef(results, 1)
```

```{R}
coef(results, 8)
```
