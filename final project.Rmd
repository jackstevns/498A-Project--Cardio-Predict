---
title: "Capstone Project"
author: "Jack Stevens"
date: "2024-04-18"
output: pdf_document
---

```{r}
data <- read.csv("cardio_train.csv", sep = ';' )
```

## Cleaning data

```{r}
data <- subset(data, ap_hi <= 200 & ap_hi >= 60)
data <- subset(data, ap_lo <= 140 & ap_lo >= 40)
data <- subset(data, select = -weight)
(num_rows <- dim(data)[1])

```
Remaining Percentage of Data

```{r}
num_rows / 70000
```

```{r}
data <-  data[-1]

```

## Converting to Factors

```{r}
data['gender'] <- as.factor(data$gender)
data['cholesterol'] <-  as.factor(data$cholesterol)
data['gluc'] <-  as.factor(data$gluc)
data['smoke'] <-  as.factor(data$smoke)
data['alco'] <- as.factor(data$alco)
data['active'] <- as.factor(data$active)
data['cardio'] <-  as.factor(data$cardio)

```

Correlation Matrix

```{r}
# Select only numeric predictors
numeric_data <- data[sapply(data, is.numeric)]
```


```{R}
# Show the numeric predictors
cor(numeric_data)

```

Standardizing Values

```{r}
numeric_data_scaled <- scale(numeric_data)
head(numeric_data_scaled)
```

```{r}
non_numeric_data <- data[sapply(data, is.factor)]
data <- data.frame(numeric_data_scaled, non_numeric_data)
```


### Number of Patients with and without Cardiovascular disease

```{r}
sum(data$cardio == 1) / 70000
sum(data$cardio == 0) / 70000
```

## Intial Logistic Model

```{r}
model <- glm(cardio ~., data = data, family = 'binomial')
summary(model)
```
### Significant Coeffiecents

```{r}
p_values <-  coef(summary(model))[, "Pr(>|z|)"]

significant_predictors <- p_values[p_values < 0.05]
(sig_predictors_names <- (names(significant_predictors[-1])))
```
### Reduced Size Model 

```{r}

model <- glm(cardio ~ age  + ap_hi + ap_lo + cholesterol + 
               gluc + smoke + alco + active, data = data, family = "binomial")

summary(model)


```

## Validation Split

```{r}
set.seed(1)
size_d <- dim(data)[1]
train_indices <- sample(size_d, size_d * .80)


```

```{r}
method <- c('logistic Regression', 'LDA', 'QDA', 'NB', 
            "Decision Tree", "KNN", "Random Forest")
```

```{r}
significant_predictors <-  c("cardio", "age", "ap_hi", "ap_lo", " cholesterol", 
              "gluc", "smoke",  "alco", "active")

selected <-  data[, which(names(data) %in% significant_predictors)]
```

```{r}
library(dplyr)
test_errors <-  numeric(7)
train_errors <-  numeric(7)
train.X <- selected[train_indices, -which(names(selected) == "cardio")]
train.Y <- selected[train_indices, "cardio"]
test.X <- selected[-train_indices, -which(names(selected) == "cardio")]
test.Y <- selected[-train_indices, "cardio"]
```



## Logistic Model 

```{r}
#logistic Classification
glm.fit = glm(cardio ~ ., data = selected,
            subset = train_indices, family = "binomial")

#compute the estimated class probability
glm.probs = predict(glm.fit, test.X, type = "response")
glm.pred = rep(0, length(test.Y))
glm.pred[glm.probs > 0.5] = 1

(test_errors[1] = 1 - mean(glm.pred == test.Y))

```



```{R}
#compute the estimated class probability
glm.probs = predict(glm.fit, train.X, type = "response")
glm.pred = rep(0, length(train.Y))
glm.pred[glm.probs > 0.5] = 1

(train_errors[1] = 1 - mean(glm.pred == train.Y))
``` 
 
## LDA 

```{r}  
library(MASS) 
  #LDA 
  lda.fit <-  lda(cardio ~ ., data = selected, 
                subset = train_indices)
  # make predictions
  lda.pred <- predict(lda.fit , test.X)
  # produce a confusion matrix
  lda.class <- lda.pred$class

  # calculate accuracy on the test set
  (test_errors[2] = 1 - mean(lda.class == test.Y))

```


```{R}
  # make predictions
  lda.pred <- predict(lda.fit , train.X)
  # produce a confusion matrix
  lda.class <- lda.pred$class

  # calculate accuracy on the test set
  (train_errors[2] = 1 - mean(lda.class == train.Y))
```

## QDA


```{r}  
  #QDA
  qda.fit <-  qda(cardio ~ . , data = selected,
                subset = train_indices)

  # make predictions
  qda.pred <- predict(qda.fit , test.X)
  
  # produce a confusion matrix
  qda.class <- qda.pred$class

  # calculate accuracy on the test set
  (test_errors[3] = 1 - mean(qda.class == test.Y))

```

```{r}

 # make predictions
  qda.pred <- predict(qda.fit , train.X)
  
  # produce a confusion matrix
  qda.class <- qda.pred$class

  # calculate accuracy on the test set
  (train_errors[3] = 1 - mean(qda.class == train.Y))
```

## Naive Bayes 

```{r}
library(e1071)
  # NB
   nb.fit <- naiveBayes(cardio ~ . ,
                      data = selected, subset = train_indices)
  # predict class labels for the test data
  nb.class = predict(nb.fit, test.X)
  # print the confusion matrix for the test data

  # compute the prediction accuracy on the test data
  (test_errors[4] = 1 - mean(nb.class == test.Y))

```

```{r}
  # predict class labels for the test data
  nb.class = predict(nb.fit, train.X)
  # print the confusion matrix for the test data

  # compute the prediction accuracy on the test data
  (train_errors[4] = 1 - mean(nb.class == train.Y))


```




## Decision Tree

```{r}
library(tree)
tree.cardio <- tree(cardio~., selected, subset = train_indices)

tree.pred <- predict(tree.cardio, test.X, type = "class")
table(tree.pred, test.Y)

(test_errors[5] <- 1 - mean(tree.pred ==  test.Y))

```

```{r}
tree.pred <- predict(tree.cardio, train.X, type = "class")
table(tree.pred, train.Y)

(train_errors[5] <- 1 - mean(tree.pred ==  train.Y))
```
```{r}
plot(tree.cardio)
text(tree.cardio, pretty = 0)

```
```{r}
## Takes a while to run
    library(class)
    k_test_error = numeric(6)
    k <- (1:6) *2 - 1

    min_test_error = 1
    k_value_test = 0

    for( i in 1:6){
        knn.pred <- knn(train.X, test.X, train.Y, k = 2*i - 1)
        test_error <- 1 - mean(test.Y == knn.pred)

        if(test_error < min_test_error){
          min_test_error <- test_error
          k_value_test <- 2*i - 1
        }
        k_test_error[i] <- test_error
      }


    plot(k,  k_test_error, xlab = "k",
         ylab = "test error", main = "Test error vs K")
    lines(k, k_test_error, col = 'red')
    points(k_value_test, min_test_error, col = "blue", pch = 19, cex = 2)

df <- data.frame(k,  k_test_error)

df

```



```{r}
knn.pred <- knn(train.X, test.X, train.Y, k = 7)
test_error <- 1 - mean(test.Y == knn.pred)
test_errors[6] <- test_error
table(knn.pred, test.Y)
```

```{r}
train_error <- 1 - mean(train.Y == knn.pred)
train_errors[6] <- train_error

```



```{r}
library(randomForest)
rf.cardio <- randomForest(cardio ~. , data = selected, subset = train_indices,
      
                                              importance = TRUE)
```

```{r}
print(1 - rf.cardio$err.rate[rf.cardio$ntree, "OOB"])

```
``

```{R}
varImpPlot(rf.cardio)

```
```{R}
#ap_hi + cholesterol + age + ap_lo + gender

```

```{r}
library(randomForest)
rf.cardio_reduced <- randomForest(cardio ~ ap_hi + age + ap_lo + gluc + active
                                  , data = selected, subset = train_indices,

                                              importance = TRUE)
```

```{r}
print(1 - rf.cardio_reduced$err.rate[rf.cardio_reduced$ntree, "OOB"])

```



```{r}
yhat.rf <- predict(rf.cardio, newdata = data[-train_indices, ])
test_errors[7] = 1 - mean(yhat.rf == test.Y)
```

```{r}
yhat.rf <- predict(rf.cardio, newdata = data[train_indices, ])
train_errors[7] = 1 - mean(yhat.rf == train.Y)
```



```{r}
accuracy_test <- 1 - test_errors
accuracy_train <- 1 - train_errors
df_interaction <- data.frame(method, test_errors, accuracy_test, train_errors, accuracy_train) 
df_sorted <- arrange(df_interaction, test_errors)
df_sorted
```
Logistic and Regression looks good. Maybe PCA / Lasso might 
help with logistic regression accuracy. This is a warming with the logistic 
regression model about converges? I don't know? 



#### testing new features in Random Forest model 
```{r}
names(data)

```

```{R}

library(randomForest)
rf.cardio_reduced <- randomForest(cardio ~ .
                                  , data = data, subset = train_indices,

                                              importance = TRUE)
```

```{r}

print(1 - rf.cardio_reduced$err.rate[rf.cardio_reduced$ntree, "OOB"])
yhat.rf <- predict(rf.cardio_reduced, newdata = data[-train_indices, ])
print( mean(yhat.rf == test.Y))
```




```{r}
varImpPlot(rf.cardio_reduced, main = "Random Forest Model-Full")

```
```{r}

library(ggplot2)
library(reshape2)

conf_matrix <- table( Actual = test.Y, Predicted = yhat.rf)

# Melt the confusion matrix
cm_melted <- melt(conf_matrix)

# Plotting the confusion matrix using ggplot2
ggplot(data = cm_melted, aes(y = Actual, x = Predicted, fill = value)) +
    geom_tile() +
    geom_text(aes(label = value), vjust = 1) +
    scale_fill_gradient(low = "white", high = "steelblue") +
    labs(title = "Confusion Matrix", y = "Actual Class", x = "Predicted Class") +
    theme_minimal()

```


```{R}

library(randomForest)
rf.cardio_reduced <- randomForest(cardio ~ ap_hi + cholesterol + age + ap_lo + gluc + height
                                  , data = data, subset = train_indices,
                                  importance = TRUE)
```

```{r}
print(1 - rf.cardio_reduced$err.rate[rf.cardio_reduced$ntree, "OOB"])
yhat.rf <- predict(rf.cardio_reduced, newdata = data[-train_indices, ])
print( mean(yhat.rf == test.Y))
```

```{r}

library(ggplot2)
library(reshape2)

conf_matrix <- table( Actual = test.Y, Predicted = yhat.rf)

# Melt the confusion matrix
cm_melted <- melt(conf_matrix)

# Plotting the confusion matrix using ggplot2
ggplot(data = cm_melted, aes(y = Actual, x = Predicted, fill = value)) +
    geom_tile() +
    geom_text(aes(label = value), vjust = 1) +
    scale_fill_gradient(low = "white", high = "steelblue") +
    labs(title = "Confusion Matrix", y = "Actual Class", x = "Predicted Class") +
    theme_minimal()

```



```{r}
test <- data[-train_indices, ]
predict.rf <- predict(rf.cardio_reduced, newdata = test, type = "prob")
library(pROC)
ROC_rf <- roc(test$cardio, predict.rf[,2])
```

```{R}
plot(ROC_rf, col = "red", main = "ROC For Random Forest")
```
```{R}
varImpPlot(rf.cardio_reduced, main = "Random Forest Model-Redcued")
```

```{r}

mtry_test <-  numeric(24)
tree_test <-  numeric(24)
accuracy <- numeric(24)
ntree <-  c(100, 300, 500, 1000)
mtrys <- c(1, 2, 3, 4, 5, 6)

```
```{r}

init <-  1
for( i in 1:4){
  for(j in 1:6){
    print(init)
    rf.cardio <- randomForest(cardio ~ ap_hi + cholesterol + age + ap_lo + gluc,
                 data = data, subset = train_indices, mtry = mtrys[j],
                 ntree = ntree[i], importance = TRUE)
    mtry_test[init] <- mtry[j]
    tree_test[init] <- ntree[i]
    yhat.rf <- predict(rf.cardio, newdata = data[-train_indices, ])
    accuracy[init] = mean(yhat.rf == test.Y)
    init <- init + 1
   
  }
}
```

```{R}
df <- arrange(data.frame(mtry_test, tree_test,accuracy), accuracy)
df

```

```{r}
arrange(df, accuracy)
```


```{r}
random_forest_tuned <-  randomForest(cardio ~ ap_hi + cholesterol + age + ap_lo + gluc 
                                  , data = data, subset = train_indices, mtry = 2, ntree = 300,
                                  importance = TRUE)
print(1 - random_forest_tuned$err.rate[300, "OOB"])
  yhat.rf <- predict(random_forest_tuned, newdata = data[-train_indices, ])
 mean(yhat.rf == test.Y)

```

#### Extra code


### Pruning Tree

```{r}
set.seed(7)

cv.cardioTree <- cv.tree(tree.cardio, FUN = prune.misclass)
```

```{R}
names(cv.cardioTree)
cv.cardioTree
```

```{R}
par(mfrow = c(1,2))
plot(cv.cardioTree$size, cv.cardioTree$dev, type = "b")
plot(cv.cardioTree$k, cv.cardioTree$dev, type = "b")

```

```{r}
prune.cardio <- prune.misclass(tree.cardio, best = 2)
plot(prune.cardio)
text(prune.cardio, pretty = 0)
```

```{r}

tree.pred <- predict(prune.cardio, test.X, type = "class")
mean(tree.pred == test.Y)

```

Same accuracy


### Under PCA
```{r}
dim(numeric_data_scaled)
```
```{r}
dim(data)

```

```{r}

pr.out <- prcomp(numeric_data, scale = TRUE)
pca_scores <- as.data.frame(pr.out$x)

```


```{r}
pca_df <- data.frame(pca_scores, non_numeric_data)
dim(pca_df)

```



```{r}
library(dplyr)
test_errors <-  numeric(6)
selected <-  pca_df
train.X <- selected[train_indices, -which(names(selected) == "cardio")]
train.Y <- selected[train_indices, "cardio"]
test.X <- selected[-train_indices, -which(names(selected) == "cardio")]
test.Y <- selected[-train_indices, "cardio"]



```

```{R}
#logistic Classification
glm.fit = glm(cardio ~ ., data = selected,
            subset = train_indices, family = "binomial")

#compute the estimated class probability
glm.probs = predict(glm.fit, test.X, type = "response")
glm.pred = rep(0, length(test.Y))
glm.pred[glm.probs > 0.5] = 1

(test_errors[1] = 1 - mean(glm.pred == test.Y))

```


### Regulization 

```{r}
library(glmnet)

x <- as.matrix(train.X)  # Predictor matrix
y <- train.Y  # Response variable

# Fit model
glmnet_model <- cv.glmnet(x, y, family = "binomial", alpha = 1)

```

```{r}
best_lambda <- glmnet_model$lambda.min

```

```{r}
# Predicting probabilities
predicted_probabilities <- predict(glmnet_model, newx = as.matrix(test.X), type = "response", s = best_lambda)

# Predicting class labels (you might need to specify a threshold, e.g., 0.5)
predicted_classes <- ifelse(predicted_probabilities > 0.5, 1, 0)

```

#### Regulization LASSO

```{R}
1 - mean(predicted_classes == test.Y)
```
```{r}
library(glmnet)

x <- as.matrix(train.X)  # Predictor matrix
y <- train.Y  # Response variable

# Fit model
glmnet_model <- cv.glmnet(x, y, family = "binomial", alpha = 0)

```

```{r}
best_lambda <- glmnet_model$lambda.min

```

```{r}
# Predicting probabilities
predicted_probabilities <- predict(glmnet_model, newx = as.matrix(test.X), type = "response", s = best_lambda)

# Predicting class labels (you might need to specify a threshold, e.g., 0.5)
predicted_classes <- ifelse(predicted_probabilities > 0.5, 1, 0)

```

#### Regulization LASSO

```{R}
1 - mean(predicted_classes == test.Y)
```

#### Without Regulation

```{r}
test_errors[1]
```

### best Subset

```{r}
library(leaps)
results <-  regsubsets(cardio ~ ., data = data, method = 'exhaustive')
reg.summary <- summary(results)

```


```{r}
plot (reg.summary$cp , xlab = " Number of Variables ", ylab = "Cp" , type = "l" )
min_cp <- which.min(reg.summary$cp)
points (min_cp , reg.summary$cp[min_cp], col = "red" , cex = 2 ,pch = 20)
min_bic <- which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC" , type = "l" )
points(min_bic , reg.summary$bic[min_bic], col = "red" , cex = 2 ,pch = 20)
min_adjr2 <- which.min(reg.summary$adjr2)
plot(reg.summary$adjr2 , xlab = "Number of Variables",
ylab = "ADJR2" , type = "l" )
points(min_adjr2 , reg.summary$adjr2[min_adjr2], col = "red" , cex = 2 ,pch = 20)



```

```{R}
coef(results, 1)
```

```{R}
coef(results, 8)
```


```{R}
library(gbm)
boost.carido <- gbm(cardio ~., data = data[train_indices,])
```

```{r}
yhat.boost <- predict(boost.carido, newdata = test.X)
(test_errors[8] <- 1 - mean(yhat.boost == test.Y))
```

```{r}
yhat.boost <- predict(boost.carido, newdata = test.X)
(train_errors[8] <- 1 - mean(yhat.boost == train.Y))
```
